temp.ts = 0
temp.ts = as.xts(deforestation.ts)
temp.ts = temp.ts["2010-01-01/2019-12-31"]
deforestation.ts = ts(as.vector(temp.ts),
start = c(substr(head(as.Date(time(temp.ts)), n = 1), 1, 4), substr(head(as.Date(time(temp.ts)), n = 1), 6, 7)),
frequency = 12)
plot.ts(deforestation.ts)
deforestation.ts
# SPEI Measurements
temp.ts = 0
temp.ts = as.xts(SPEI3.ts)
temp.ts = temp.ts["2010-01-01/2019-12-31"]
SPEI3.ts = ts(as.vector(temp.ts),
start = c(substr(head(as.Date(time(temp.ts)), n = 1), 1, 4), substr(head(as.Date(time(temp.ts)), n = 1), 6, 7)),
frequency = 12)
plot.ts(SPEI3.ts)
SPEI3.ts
####~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~####
#..............................................................................#
####   5. UNIVARIATE ANALYSIS                                               ####
#..............................................................................#
####~~~~~~~~~~~~~~~####
#..............................................................................#
####   5i. Model Selection                                               ####
#..............................................................................#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.a. Plot TS ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
ggtsdisplay(x = futures.ts,
xlab="Date",
main="futures.ts")
plot.ts(futures.ts)
# We have a trend
# Variance issue
# Plots don't imply seasonality
# Correlograms
acf(futures.ts, lag=84, plot = T) # Lots of volatility
pacf(futures.ts, lag=84, plot = T) # lags = 1, 2, 14
# Seasonality Plot
monthplot(futures.ts)
ggseasonplot(futures.ts, year.labels=TRUE, year.labels.left=TRUE)
ggseasonplot(futures.ts, polar=TRUE)
# Look at smaller windows of data
plot.ts(futures.ts[1:12])      # first year
plot.ts(futures.ts[13:24])     # Second year
plot.ts(futures.ts[25:36])     # third year
plot.ts(futures.ts[37:48])     # fourth year
plot.ts(futures.ts[49:60])     # fifth year
plot.ts(futures.ts[61:72])     # sixth year
plot.ts(futures.ts[73:84])     # seventh year
plot.ts(futures.ts[85:96])     # eighth year
plot.ts(futures.ts[97:108])     # ninth year
plot.ts(futures.ts[109:120])     # tenth year
# Cocoa beans are harvested twice a year in IC (Big H: Oct-Mar) and (Smaller H: May-Aug)
# It makes sense to see the future costs have two maximums a year near the end of the harvest seasons
# as the supply of recent collections will diminish.
# The political unrest in 2010-2011 and 2017 lead to either the pullout of many international banks (2011) or
# to many foreign investors holding off their investment (2017). Both caused the price of cocoa beans to drop
# 2011: https://cn.reuters.com/article/us-ivorycoast-socgen-idUSTRE71G09920110217
# 2017: https://fr.reuters.com/article/ozabs-uk-cocoa-ivorycoast-grinders-idAFKBN15F0K7
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.b. Log of Futures                            ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
log.futures.ts = log(futures.ts)
ggtsdisplay(x = log.futures.ts,
xlab="Date",
main="log.futures.ts")
plot.ts(log.futures.ts)
# Correlogram
acf(log.futures.ts, lag=84, plot = T)
pacf(log.futures.ts, lag=84, plot = T) # lags = 1, 2, 14
# Seasonality Plot
monthplot(log.futures.ts)
ggseasonplot(log.futures.ts, year.labels=TRUE, year.labels.left=TRUE)
ggseasonplot(log.futures.ts, polar=TRUE)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.c. 1st ADF Test WITH Trend                            ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
max.lag = round(sqrt(length(log.futures.ts)))
mytest = CADFtest(log.futures.ts, type = "trend", criterion = "BIC", max.lag.y = max.lag)
summary(mytest)
# H0: not stationary (stochastic trend)
# p-value = 0.713
# Fail to reject H0 i.e., TS not stationary & trend is stochastic, use differences
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.d. Log-Diff TS Plot ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
d.log.futures.ts = diff(log.futures.ts)
ggtsdisplay(x = d.log.futures.ts,
xlab="Date",
main="d.log.futures.ts")
plot.ts(d.log.futures.ts)
# mean = zero
# Variance cond. heterosced. (Check res^2)
# Looks more stationary
# Correlograms
acf(d.log.futures.ts, lag=84, plot = T)  # signif lag 1 & 18 (barely)
pacf(d.log.futures.ts, lag=84, plot = T) # signif lag 1 (barely)
# Seasonality Plot
monthplot(d.log.futures.ts)
ggseasonplot(d.log.futures.ts, year.labels=TRUE, year.labels.left=TRUE)
ggseasonplot(d.log.futures.ts, polar=TRUE)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.e. 2st ADF Test w/o Trend                             ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
max.lag = round(sqrt(length(d.log.futures.ts)))
mytest = CADFtest(d.log.futures.ts , type = "drift", criterion = "BIC", max.lag.y = max.lag)
summary(mytest)
# H0: not stationary
# p-value = 1.34e-11
# REJECT H0 i.e., diff(log(TS)) is stationary
# But var still cond. heterosced.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.f. Q-test for White Noise                            ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
max.lag = round(sqrt(length(d.log.futures.ts)))
Box.test(d.log.futures.ts, lag = max.lag, type = "Ljung-Box")
# H0: corrs are zero (i.e., white noise)
# p-value = 0.4733
# FAIL to reject H0 i.e., diff(log(TS)) is WHITE NOISE
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5i.f. PPT Plots                            ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# original futures.ts & transformed d.log.futures.ts
fp.plots=autoplot(cbind(futures.ts, d.log.futures.ts), facets=TRUE) +
theme_bw(base_size = 15) +
scale_x_yearmon(n=5) +
theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
xlab("Date") +
ylab("GBP/tonne")  +
ggtitle("Transformations of Future Prices")
fp.plots
# d.log.futures.ts ACF
dlog.acf = ggAcf(d.log.futures.ts, lag = 36) + ggtitle("ACF: Log-Diff TS") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
# d.log.futures.ts PACF
dlog.pacf = ggPacf(d.log.futures.ts, lag = 36) + ggtitle("PACF: Log-Diff TS") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
# d.log.futures.ts^2 ACF
dlog.acf2 = ggAcf(d.log.futures.ts^2, lag = 36) +  ggtitle("ACF: Log-Diff TS^2") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
# Combine all d.log.future.ts model spec plots
ggarrange(ggarrange(dlog.acf, dlog.pacf, dlog.acf2, ncol = 3), nrow = 1)
####~~~~~~~~~~~~~~~####
#..............................................................................#
####   5ii. Model Estimation                                               ####
#..............................................................................#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5ii.a Model building                             ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# ARIMA(1,1,0) Estimation
model.110 = arima(x = log.futures.ts, order = c(1,1,0))
summary(model.110)
# P-value for significance
(1-pnorm(abs(model.110$coef/sqrt(diag(model.110$var.coef)))))*2
# AR1 coef is significant
# ARIMA(0,1,0) Estimation
model.010 = arima(x = log.futures.ts, order = c(0,1,0))
summary(model.010)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5ii.b Residual Plots, Correlograms, & Q-test ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# Plot model.010
ggtsdisplay(x = model.110$residuals, xlab="Date", main="model.110$residuals") # still cond. heterosced.
# Correlogram
acf(model.110$residuals, lag= 12*9, xlab="Date", main="model.110$residuals") # lag = 3, 17
# Q-test
Box.test(model.110$residuals, lag = max.lag, type = "Ljung-Box") # p-val = 0.889 (WN)
# All WN, but var still cond. hetero.
# Plot model.010
ggtsdisplay(x = model.010$residuals, xlab="Date", main="model.010$residuals") # still cond. heterosced.
# Correlogram
acf(model.010$residuals, lag= 12*9, xlab="Date", main="model.010$residuals")$acf # lag = 1, 17
# Q-test
Box.test(model.010$residuals, lag = max.lag, type = "Ljung-Box") # p-val = 0.445 (WN)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5ii.c Residual^2 Plots, Correlograms, & Q-test ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# Plot model.010
ggtsdisplay(x = model.110$residuals^2, xlab="Date", main="model.110$residuals")
# Correlogram
acf(model.110$residuals^2, lag= 12*9, xlab="Date", main="model.110$residuals") # lag = 3, 7
# Q-test
Box.test(model.110$residuals^2, lag = max.lag, type = "Ljung-Box") # p-val = 0.031 (not WN)
# Plot model.010
ggtsdisplay(x = model.010$residuals^2, xlab="Date", main="model.010$residuals")
# Correlogram
acf(model.010$residuals^2, lag= 12*9, xlab="Date", main="model.010$residuals")$acf # lag = 3, 15, 75
# Q-test
Box.test(model.010$residuals^2, lag = max.lag, type = "Ljung-Box") # p-val = 0.083 (WN)
####~~~~~~~~~~~~~~~####
#..............................................................................#
####   5iii. GARCH Model Estimation                                         ####
#..............................................................................#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5ii.a Model Building ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# ARIMA(1,1,0) + GARCH(1,1)
model.110.garch = garchFit( ~ arma(1,0) + garch(1,1), data = d.log.futures.ts)
summary(model.110.garch)
#plot(model.110.garch)
# std.Residuals are normal (JB & SW tests)
# std.Residuals are WN (LB Test), ACF looks OK
# std.Residuals^2 are NOT WN (LB Test) but ACF shows small signif lags at 5 & 7
# mu, omega, & alpha1 (past residual) not significant
# beta is significant, past volatility influences current volatility
# Conditional SD shows volatility
# LM Arch Test (H0: no arch effects) pval=0.028 (still arch)
# ARIMA(0,1,0) + GARCH(1,1)
model.010.garch = garchFit( ~ garch(1,1), data = d.log.futures.ts, include.mean = F)
summary(model.010.garch)
#plot(model.010.garch)
# std.Residuals are normal: JB test (pval = 0.27) & SW tests (pval = 0.061)
# std.Residuals are WN (LB Test), ACF looks OK (lag 1, 13, 17 close)
# std.Residuals^2 are NOT WN (LB Test) but ACF shows small signif lags at 7, 8, 9, 15, 16
# omega, & alpha1 (past residual) not significant
# beta is significant, past volatility influences current volatility
# Conditional SD shows volatility
# LM Arch Test (H0: no arch effects) pval=0.04 (still arch)
# ARIMA(1,1,0) + GARCH(2,1)
model.110.garch.21 = garchFit( ~ arma(1,0) + garch(2,1), data = d.log.futures.ts)
summary(model.110.garch.21)
# Std.residuals^2 are WN
# alplha2 & beta1 significant
# LM ARCH Test pval=0.182 (no ARCH)
# ARIMA(0,1,0) + GARCH(2,1)
model.010.garch.21= garchFit( ~ garch(2,1), data = d.log.futures.ts, include.mean = F)
summary(model.010.garch.21)
# Std.residuals^2 are WN
# alplha2 & beta1(pval=0.678) significant
# LM ARCH Test pval=0.32 (no ARCH)
####~~~~~~~~~~~~~~~####
#..............................................................................#
####   5iv. Model Forecasting                                         ####
#..............................................................................#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.a In-Sample Errors ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# ARIMA(1,1,0) AIC/BIC in garchFit are scaled by size of TS
AIC(model.110)/length(log.futures.ts)
BIC(model.110)/length(log.futures.ts)
# ARIMA(0,1,0) AIC/BIC in garchFit are scaled by size of TS
AIC(model.010)/length(log.futures.ts)
BIC(model.010)/length(log.futures.ts)
# GARCH(1,1)
summary(model.110.garch)
summary(model.010.garch)
# GARCH(2,1)
summary(model.110.garch.21)
summary(model.010.garch.21)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.b Function for Out-of-Sample Validation ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# A function to run the  out of sample cross-validation and obtain GOF stats
# data.y = dataset
# p = % of data.y for training set
# h = h-step forecast
# ARp.m = AR(p) value
# diff.I.m = order of integration
# MAq.m = MA(q) value
# G1.m & G2.m =  GARCH(GA1, GA2)
CV_OSS <- function(data.y, perc, h.step, ARp.m, diff.I.m, MAq.m, G1.m, G2.m){
# Create the training set (S) and the test set (h)
y <- data.y
S <- round(perc*length(y))
h <- h.step
ARp <- ARp.m
diff.I <- diff.I.m
MAq <- MAq.m
G1 <- G1.m
G2 <- G2.m
error.h <- c()
for(i in S:(length(y)-h)){
# Decide which model to use ARIMA, GARCH, ARMA+GARCH
if((G1 == 0) && (G2 == 0)){
mymodel.sub <- arima(y[1:i], order = c(ARp, diff.I, MAq))
} else if((ARp == 0) && (MAq == 0)){
mymodel.sub <- garchFit(substitute( ~ garch(pp, qq), list(pp = G1, qq = G2)), data = y[1:i], include.mean = F)
} else {
mymodel.sub <- garchFit(substitute( ~ arma(p, q) + garch(pp, qq), list(p = ARp, q = MAq, pp = G1, qq = G2)), data = y[1:i])
}
# Make the predict & calculate the error
ifelse((G1 == 0) && (G2 == 0),
predict.h <- predict(mymodel.sub, n.ahead = h)$pred[h],
predict.h <- predict(mymodel.sub, n.ahead = h)$meanForecast[h])
error.h <- c(error.h, y[i+h] - predict.h)
}
return(error.h)
}  #click tab on the left for full function
# Function that returns Root Mean Squared Error
rmse <- function(error){
sqrt(mean(error^2, na.rm = T))
}
# Function that returns Mean Absolute Error
mae <- function(error){
mean(abs(error), na.rm = T)
}
# ARIMA(1,1,0) FOR log.futures.ts
error.model.110 = list(CV_OSS(log.futures.ts, 0.60, 1, 1, 1, 0, 0, 0), # perc = .60 / 1-step
CV_OSS(log.futures.ts, 0.60, 2, 1, 1, 0, 0, 0), # perc = .60 / 3-step
CV_OSS(log.futures.ts, 0.60, 6, 1, 1, 0, 0, 0), # perc = .60 / 6-step
CV_OSS(log.futures.ts, 0.60, 12, 1, 1, 0, 0, 0), # perc = .60 / 12-step
CV_OSS(log.futures.ts, 0.80, 1, 1, 1, 0, 0, 0), # perc = .80 / 1-step
CV_OSS(log.futures.ts, 0.80, 3, 1, 1, 0, 0, 0), # perc = .80 / 3-step
CV_OSS(log.futures.ts, 0.80, 6, 1, 1, 0, 0, 0), # perc = .80 / 6-step
CV_OSS(log.futures.ts, 0.80, 12, 1, 1, 0, 0, 0)) # perc = .80 / 12-step
error.model.110 = data.frame(lapply(error.model.110, "length<-", max(lengths(error.model.110))))
colnames(error.model.110) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
# ARIMA(0,1,0) FOR log.futures.ts
error.model.010 = list(CV_OSS(log.futures.ts, 0.60, 1, 0, 1, 0, 0, 0), # perc = .60 / 1-step
CV_OSS(log.futures.ts, 0.60, 2, 0, 1, 0, 0, 0), # perc = .60 / 3-step
CV_OSS(log.futures.ts, 0.60, 6, 0, 1, 0, 0, 0), # perc = .60 / 6-step
CV_OSS(log.futures.ts, 0.60, 12, 0, 1, 0, 0, 0), # perc = .60 / 12-step
CV_OSS(log.futures.ts, 0.80, 1, 0, 1, 0, 0, 0), # perc = .80 / 1-step
CV_OSS(log.futures.ts, 0.80, 3, 0, 1, 0, 0, 0), # perc = .80 / 3-step
CV_OSS(log.futures.ts, 0.80, 6, 0, 1, 0, 0, 0), # perc = .80 / 6-step
CV_OSS(log.futures.ts, 0.80, 12, 0, 1, 0, 0, 0)) # perc = .80 / 12-step
error.model.010 = data.frame(lapply(error.model.010, "length<-", max(lengths(error.model.010))))
colnames(error.model.010) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
# ARIMA(1,0,0)+GARCH(1,1) FOR d.log.futures.ts
error.model.110.garch.11 = list(CV_OSS(d.log.futures.ts, 0.60, 1, 1, 0, 0, 1, 1), # perc = .60 / 1-step
CV_OSS(d.log.futures.ts, 0.60, 2, 1, 0, 0, 1, 1), # perc = .60 / 3-step
CV_OSS(d.log.futures.ts, 0.60, 6, 1, 0, 0, 1, 1), # perc = .60 / 6-step
CV_OSS(d.log.futures.ts, 0.60, 12, 1, 0, 0, 1, 1), # perc = .60 / 12-step
CV_OSS(d.log.futures.ts, 0.80, 1, 1, 0, 0, 1, 1), # perc = .80 / 1-step
CV_OSS(d.log.futures.ts, 0.80, 3, 1, 0, 0, 1, 1), # perc = .80 / 3-step
CV_OSS(d.log.futures.ts, 0.80, 6, 1, 0, 0, 1, 1), # perc = .80 / 6-step
CV_OSS(d.log.futures.ts, 0.80, 12, 1, 0, 0, 1, 1)) # perc = .80 / 12-step
error.model.110.garch.11 = data.frame(lapply(error.model.110.garch.11, "length<-", max(lengths(error.model.110.garch.11))))
colnames(error.model.110.garch.11) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
# ARIMA(0,1,0)+GARCH(1,1) FOR d.log.futures.ts
error.model.010.garch.11 = list(CV_OSS(d.log.futures.ts, 0.60, 1, 0, 0, 0, 1, 1), # perc = .60 / 1-step
CV_OSS(d.log.futures.ts, 0.60, 2, 0, 0, 0, 1, 1), # perc = .60 / 3-step
CV_OSS(d.log.futures.ts, 0.60, 6, 0, 0, 0, 1, 1), # perc = .60 / 6-step
CV_OSS(d.log.futures.ts, 0.60, 12, 0, 0, 0, 1, 1), # perc = .60 / 12-step
CV_OSS(d.log.futures.ts, 0.80, 1, 0, 0, 0, 1, 1), # perc = .80 / 1-step
CV_OSS(d.log.futures.ts, 0.80, 3, 0, 0, 0, 1, 1), # perc = .80 / 3-step
CV_OSS(d.log.futures.ts, 0.80, 6, 0, 0, 0, 1, 1), # perc = .80 / 6-step
CV_OSS(d.log.futures.ts, 0.80, 12, 0, 0, 0, 1, 1)) # perc = .80 / 12-step
error.model.010.garch.11 = data.frame(lapply(error.model.010.garch.11, "length<-", max(lengths(error.model.010.garch.11))))
colnames(error.model.010.garch.11) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
# ARIMA(1,0,0)+GARCH(2,1) FOR d.log.futures.ts
error.model.110.garch.21 = list(CV_OSS(d.log.futures.ts, 0.60, 1, 1, 0, 0, 2, 1), # perc = .60 / 1-step
CV_OSS(d.log.futures.ts, 0.60, 2, 1, 0, 0, 2, 1), # perc = .60 / 3-step
CV_OSS(d.log.futures.ts, 0.60, 6, 1, 0, 0, 2, 1), # perc = .60 / 6-step
CV_OSS(d.log.futures.ts, 0.60, 12, 1, 0, 0, 2, 1), # perc = .60 / 12-step
CV_OSS(d.log.futures.ts, 0.80, 1, 1, 0, 0, 2, 1), # perc = .80 / 1-step
CV_OSS(d.log.futures.ts, 0.80, 3, 1, 0, 0, 2, 1), # perc = .80 / 3-step
CV_OSS(d.log.futures.ts, 0.80, 6, 1, 0, 0, 2, 1), # perc = .80 / 6-step
CV_OSS(d.log.futures.ts, 0.80, 12, 1, 0, 0, 2, 1)) # perc = .80 / 12-step
error.model.110.garch.21 = data.frame(lapply(error.model.110.garch.21, "length<-", max(lengths(error.model.110.garch.21))))
colnames(error.model.110.garch.21) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
# ARIMA(0,1,0)+GARCH(2,1) FOR d.log.futures.ts
error.model.010.garch.21 = list(CV_OSS(d.log.futures.ts, 0.60, 1, 0, 0, 0, 2, 1), # perc = .60 / 1-step
CV_OSS(d.log.futures.ts, 0.60, 2, 0, 0, 0, 2, 1), # perc = .60 / 3-step
CV_OSS(d.log.futures.ts, 0.60, 6, 0, 0, 0, 2, 1), # perc = .60 / 6-step
CV_OSS(d.log.futures.ts, 0.60, 12, 0, 0, 0, 2, 1), # perc = .60 / 12-step
CV_OSS(d.log.futures.ts, 0.80, 1, 0, 0, 0, 2, 1), # perc = .80 / 1-step
CV_OSS(d.log.futures.ts, 0.80, 3, 0, 0, 0, 2, 1), # perc = .80 / 3-step
CV_OSS(d.log.futures.ts, 0.80, 6, 0, 0, 0, 2, 1), # perc = .80 / 6-step
CV_OSS(d.log.futures.ts, 0.80, 12, 0, 0, 0, 2, 1)) # perc = .80 / 12-step
error.model.010.garch.21 = data.frame(lapply(error.model.010.garch.21, "length<-", max(lengths(error.model.010.garch.21))))
colnames(error.model.010.garch.21) = c("p60h1", "p60h3", "p60h6", "p60h12", "p80h1", "p80h3", "p80h6", "p80h12")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.c  Out-of-Sample Measurements data frames ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# Training set = 60%(full TS)
error.p60 = c()
error.p60 = rbind(c(1, 1, rmse(error.model.110$p60h1), mae(error.model.110$p60h1)),
c(1, 3, rmse(error.model.110$p60h3), mae(error.model.110$p60h3)),
c(1, 6, rmse(error.model.110$p60h6), mae(error.model.110$p60h6)),
c(1, 12, rmse(error.model.110$p60h12), mae(error.model.110$p60h12)),
c(2, 1, rmse(error.model.010$p60h1), mae(error.model.010$p60h1)),
c(2, 3, rmse(error.model.010$p60h3), mae(error.model.010$p60h3)),
c(2, 6, rmse(error.model.010$p60h6), mae(error.model.010$p60h6)),
c(2, 12, rmse(error.model.010$p60h12), mae(error.model.010$p60h12)),
c(3, 1, rmse(error.model.110.garch.11$p60h1), mae(error.model.110.garch.11$p60h1)),
c(3, 3, rmse(error.model.110.garch.11$p60h3), mae(error.model.110.garch.11$p60h3)),
c(3, 6, rmse(error.model.110.garch.11$p60h6), mae(error.model.110.garch.11$p60h6)),
c(3, 12, rmse(error.model.110.garch.11$p60h12), mae(error.model.110.garch.11$p60h12)),
c(4, 1, rmse(error.model.010.garch.11$p60h1), mae(error.model.010.garch.11$p60h1)),
c(4, 3, rmse(error.model.010.garch.11$p60h3), mae(error.model.010.garch.11$p60h3)),
c(4, 6, rmse(error.model.010.garch.11$p60h6), mae(error.model.010.garch.11$p60h6)),
c(4, 12, rmse(error.model.010.garch.11$p60h12), mae(error.model.010.garch.11$p60h12)),
c(5, 1, rmse(error.model.110.garch.21$p60h1), mae(error.model.110.garch.21$p60h1)),
c(5, 3, rmse(error.model.110.garch.21$p60h3), mae(error.model.110.garch.21$p60h3)),
c(5, 6, rmse(error.model.110.garch.21$p60h6), mae(error.model.110.garch.21$p60h6)),
c(5, 12, rmse(error.model.110.garch.21$p60h12), mae(error.model.110.garch.21$p60h12)),
c(6, 1, rmse(error.model.010.garch.21$p60h1), mae(error.model.010.garch.21$p60h1)),
c(6, 3, rmse(error.model.010.garch.21$p60h3), mae(error.model.010.garch.21$p60h3)),
c(6, 6, rmse(error.model.010.garch.21$p60h6), mae(error.model.010.garch.21$p60h6)),
c(6, 12, rmse(error.model.010.garch.21$p60h12), mae(error.model.010.garch.21$p60h12)))
error.p60 = data.frame(error.p60)
colnames(error.p60) = c("Model", "hStep", "RMSE", "MAE")
error.p60$Model = as.factor(error.p60$Model)
error.p60$hStep = as.factor(error.p60$hStep)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# Training set = 80%(full TS)
error.p80 = c()
error.p80 = rbind(c(1, 1, rmse(error.model.110$p80h1), mae(error.model.110$p80h1)),
c(1, 3, rmse(error.model.110$p80h3), mae(error.model.110$p80h3)),
c(1, 6, rmse(error.model.110$p80h6), mae(error.model.110$p80h6)),
c(1, 12, rmse(error.model.110$p80h12), mae(error.model.110$p80h12)),
c(2, 1, rmse(error.model.010$p80h1), mae(error.model.010$p80h1)),
c(2, 3, rmse(error.model.010$p80h3), mae(error.model.010$p80h3)),
c(2, 6, rmse(error.model.010$p80h6), mae(error.model.010$p80h6)),
c(2, 12, rmse(error.model.010$p80h12), mae(error.model.010$p80h12)),
c(3, 1, rmse(error.model.110.garch.11$p80h1), mae(error.model.110.garch.11$p80h1)),
c(3, 3, rmse(error.model.110.garch.11$p80h3), mae(error.model.110.garch.11$p80h3)),
c(3, 6, rmse(error.model.110.garch.11$p80h6), mae(error.model.110.garch.11$p80h6)),
c(3, 12, rmse(error.model.110.garch.11$p80h12), mae(error.model.110.garch.11$p80h12)),
c(4, 1, rmse(error.model.010.garch.11$p80h1), mae(error.model.010.garch.11$p80h1)),
c(4, 3, rmse(error.model.010.garch.11$p80h3), mae(error.model.010.garch.11$p80h3)),
c(4, 6, rmse(error.model.010.garch.11$p80h6), mae(error.model.010.garch.11$p80h6)),
c(4, 12, rmse(error.model.010.garch.11$p80h12), mae(error.model.010.garch.11$p80h12)),
c(5, 1, rmse(error.model.110.garch.21$p80h1), mae(error.model.110.garch.21$p80h1)),
c(5, 3, rmse(error.model.110.garch.21$p80h3), mae(error.model.110.garch.21$p80h3)),
c(5, 6, rmse(error.model.110.garch.21$p80h6), mae(error.model.110.garch.21$p80h6)),
c(5, 12, rmse(error.model.110.garch.21$p80h12), mae(error.model.110.garch.21$p80h12)),
c(6, 1, rmse(error.model.010.garch.21$p80h1), mae(error.model.010.garch.21$p80h1)),
c(6, 3, rmse(error.model.010.garch.21$p80h3), mae(error.model.010.garch.21$p80h3)),
c(6, 6, rmse(error.model.010.garch.21$p80h6), mae(error.model.010.garch.21$p80h6)),
c(6, 12, rmse(error.model.010.garch.21$p80h12), mae(error.model.010.garch.21$p80h12)))
error.p80 = data.frame(error.p80)
colnames(error.p80) = c("Model", "hStep", "RMSE", "MAE")
error.p80$Model = as.factor(error.p80$Model)
error.p80$hStep = as.factor(error.p80$hStep)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.d Smallest RMSE & MAE Models ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# For each model, which S & h provides the smallest RMSE
error.p60 %>%
group_by(Model) %>%
slice(which.min(RMSE))
error.p80 %>%
group_by(Model) %>%
slice(which.min(RMSE))
# For each model, which S & h provides the smallest MAE
error.p60 %>%
group_by(Model) %>%
slice(which.min(MAE))
error.p80 %>%
group_by(Model) %>%
slice(which.min(MAE))
# Determine which models have the lowest values
which(error.p60$RMSE == min(error.p60$RMSE))
# RMSE=0.05072842, model=ARIMA(1,1,0), Train=60%, hStep=1
which(error.p60$MAE == min(error.p60$MAE))
# MAE =0.03767914, model=ARIMA(1,1,0)+GARCH(2,1), Train=60%, hStep=1
which(error.p80$RMSE == min(error.p80$RMSE))
# RMSE=0.03385167, model=ARIMA(0,1,0)+GARCH(1,1), Train=80%, hStep=12
# RMSE=0.03385167, model=ARIMA(0,1,0)+GARCH(2,1), Train=80%, hStep=12
which(error.p80$MAE == min(error.p80$MAE))
# MAE =0.02735079, model=ARIMA(0,1,0)+GARCH(1,1), Train=80%, hStep=12
# MAE =0.02735079, model=ARIMA(0,1,0)+GARCH(2,1), Train=80%, hStep=12
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.e  Diebold-Mariano Forecast Test ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=12, power=1)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=12, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=12, power=1)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=1, power=1)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=1, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=12, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=11, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=9, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=4, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=2, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=1, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=0, power=2)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=12, power=1)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=12, power=1)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=1, power=1)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=1, power=2)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=12, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.010.garch.21$p80h12, h=12, power=2)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=12, power=2)
dm.test(error.model.110.garch.21$p80h12, error.model.010.garch.21$p80h12, h=12, power=2)
dm.test(error.model.010.garch.21$p80h12, error.model.110.garch.21$p80h12, h=11, power=2)
dm.test(error.model.110.garch.21$p80h12, error.model.010.garch.21$p80h12, h=11, power=2)
dm.test(error.model.010.garch.11$p80h12, error.model.110.garch.21$p80h12, h=12, power=2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
#### 5iv.f  Plot of selected model vs Data ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
plot(model.010.garch.21)
?garchFit
testModel=garchFit( ~ garch(2,1), data = d.log.futures.ts, include.mean = F, cond.dist = "QMLE")
summary(testModel)
#..............................................................................#
####   Load Packages                                                        ####
#..............................................................................#
libraries = c('readxl', 'haven', 'tidyverse', 'data.table', 'psych', 'MVN',
'ggpubr', 'gridExtra', 'MASS', 'PerformanceAnalytics', 'olsrr',
'car', 'robustbase')
sapply(libraries, require, character.only = T)
install.packages(c("commonmark", "crayon", "DEoptimR", "desc", "fansi", "gert", "igraph", "knitr", "lavaan", "lmtest", "magrittr", "MplusAutomation", "OpenMx", "pander", "plyr", "processx", "psych", "RColorBrewer", "Rcpp", "RcppArmadillo", "readxl", "rlang", "robustbase", "rprojroot", "sass", "testthat", "texreg", "tidySEM", "tinytex", "tseries", "tzdb", "vctrs", "waldo"))
#..............................................................................#
####   Load Packages                                                        ####
#..............................................................................#
libraries = c('readxl', 'haven', 'tidyverse', 'data.table', 'psych', 'MVN',
'ggpubr', 'gridExtra', 'MASS', 'PerformanceAnalytics', 'olsrr',
'car', 'robustbase')
sapply(libraries, require, character.only = T)
warnings()
Survey.Data2019 = read_excel("../Data/2019-public-data-file_student.xlsx", sheet = "Student # of Resp")
NYC.Regents.Data = read.csv("../Data/2014-15_to_2017-19_NYC_Regents_Exam_Results_-_Public.csv")
demographic_snapshot = read_excel("../Data/demographic-snapshot-2014-15-to-2018-19-(public).xlsx", sheet = "School")
Survey.Data2019 = read_excel("./Data/2019-public-data-file_student.xlsx", sheet = "Student # of Resp")
getwd()
